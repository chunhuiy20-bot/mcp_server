# msc 概念
## 1、msc 实现原理推测
```txt
msc(model set context)概念: ChatGPT 能跨会话记住我们的信息，比如：技术栈（会 Python、React 等）、偏好（喜欢简洁回答、用中文等）、工作背景、之前提到的项目细节。  
实现原理[推测,目前也不确定]:
1、存储层：用户级别的 key-value 或向量数据库，存储提取出的记忆片段  
2、提取时机：对话中检测到值得记住的信息时（通过模型判断），自动提取并存储  
3、注入时机：每次新会话开始时，相关记忆被拼接到 system prompt 里  
4、检索方式：可能是全量加载，也可能根据当前对话内容做语义检索（RAG）  
```

## 2、msc 存在的问题
```txt
1、存储层存在的问题: key-value 的方式只能记住简短的信息，但是详细信息不行，比如用户和ai对话的一些项目细节无法全部记住。适用于记住一些标签信息。
2、注入时机: 如果是在每个会话的开头，全量注入信息并不一定是一种好的实现方式，因为一旦信息过多，在初始的时候就会消耗过多的token，导致上下文窗口很快被用完
```

## 3、msc 优化的思考

### 3.1 优化目标 
```txt
1、 需要能记住具体细节
2、 保持原有的轻量化
3、 注入时机应该动态
```    

### 3.2 如何保持原有的轻量化的同时能记住具体细节 
```txt
方式1：
可以考虑图数据库，以用户实体为中心，长期有效且简短的信息直接保存在用户实体,比如: 用户生日、技能、专业、爱好、技术偏好等。  
一些比较长且有细节的消息，可以以用户为中心，创建其他实体，这些含有细节的详细信息可以做摘要并在用户与其他实体之间的关系边中记录。
当触发查询的时候，只查询用户实体信息和连接用户实体的边的摘要信息【入度或出度】，如果这些消息无法回答当前的问题，可以继续进行图的深度遍历。
优点：
1、分层存储：核心属性在用户节点，细节在关联实体，摘要在边上
2、按需检索：先浅后深，避免一次性加载过多
3、保留细节的同时控制 token 消耗
难点在于：
1、写入时机如何控制？
   不是每句话都值得建实体，否则会导致图的复杂性爆炸，所以需要一个"重要性判断"模块，但是这个重要性判断又该如何衡量？
   实时抽取？冲突处理？图的膨胀控制？
2、边的摘要质量
   摘要太粗会丢失触发深度遍历的线索
流程大概：
    用户消息 
      ↓
    重要性判断（轻量分类器或 LLM）
      ↓ 值得记录
    实体/关系抽取
      ↓
    与现有图对比（新增/更新/冲突？）
      ↓
    写入图数据库
      ↓
    异步：触发相关社区摘要更新
```
